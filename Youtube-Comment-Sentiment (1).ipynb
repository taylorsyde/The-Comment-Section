{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976dcb5b",
   "metadata": {},
   "source": [
    "## Import Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f046e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping tools\n",
    "from urllib.error import HTTPError\n",
    "from datetime import datetime\n",
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# NLP tools\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#import API key\n",
    "from keys import magic_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d4e1e4",
   "metadata": {},
   "source": [
    "### Get YouTube Transcript (Currently Broken)\n",
    "\n",
    "Apparently you can't scrape the transcripts the old fashioned way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa474799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Drop in the link to the youtube video.\")\n",
    "# url = input()\n",
    "\n",
    "# # https://www.youtube.com/watch?v=jCZKEnThrjI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68505a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (f'Your url is {url}')\n",
    "# with request.urlopen(url) as response:\n",
    "#     resp = response.read()\n",
    "#     soup = bs(resp, \"html.parser\")\n",
    "#     print(\"Your youtube soup is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b36e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd65b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pull in title and transcript from the soup\n",
    "# lil_soup = soup.find_all(\"div\", id_=\"segments-container\")\n",
    "# print(lil_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d13e1",
   "metadata": {},
   "source": [
    "### Youtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8357e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for getting Youtube comments with the Youtube API\n",
    "def get_comments():\n",
    "    \n",
    "    #get the parameters url from the user and create a \n",
    "    video_url = input(\"Drop in the Youtube Link: \")\n",
    "    print ('Got it! Thanks')\n",
    "    video_id = video_url[32:] #extract the video id from the url\n",
    "    # print(video_id)\n",
    "    \n",
    "    num_comments = input(\"How many comments do you what to explore? \")\n",
    "    max_comments = re.sub('[^0-9]','', num_comments) #drop any letters\n",
    "    print(f'{max_comments}, huh? Whatever you say boss.')\n",
    "    # print(max_comments)\n",
    "    \n",
    "    # init API query\n",
    "    base_url = f\"https://www.googleapis.com/youtube/v3/commentThreads?key={magic_key}\"\n",
    "    params = f\"&textFormat=plainText&part=snippet&videoId={video_id}&maxResults={max_comments}\"\n",
    "    \n",
    "    #CALL API\n",
    "    query_url = base_url + params\n",
    "    response = requests.get(query_url).json()\n",
    "    \n",
    "    \n",
    "    # LOOP THRU COMMENTS AND GET THAT YUMMY COMMENT TEXT\n",
    "    # response['items'][10] # this is the format of a SINGLE COMM\n",
    "    #raw_comment_list = response['items']\n",
    "\n",
    "    num_comments = response['pageInfo']['totalResults'] # number of comments acutally returned from API\n",
    "    counter = np.arange(0,num_comments) # create list to count thru\n",
    "    print(f'We found {num_comments} comments on this video.')\n",
    "\n",
    "    comments = []\n",
    "    for c in counter:\n",
    "        comment_text = response['items'][c]['snippet']['topLevelComment']['snippet']['textOriginal']\n",
    "        #print(comment_text)\n",
    "        #print('------------------')\n",
    "        comments.append(comment_text)\n",
    "        \n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10269e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop in the Youtube Link: https://www.youtube.com/watch?v=DfWQLbIHPPk\n",
      "Got it! Thanks\n",
      "How many comments do you what to explore? 10\n",
      "10, huh? Whatever you say boss.\n",
      "We found 10 comments on this video.\n"
     ]
    }
   ],
   "source": [
    "comments = get_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f792841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh Iâ€™ve missed you! Iâ€™ve been worried because you havenâ€™t posted ðŸ™‚ How are you holding up?\n",
      "{'neg': 0.251, 'neu': 0.749, 'pos': 0.0, 'compound': -0.5707}\n",
      "-------------\n",
      "No, it isnâ€™t.  (At least not anywhere that Iâ€™m aware of.)\n",
      "{'neg': 0.18, 'neu': 0.82, 'pos': 0.0, 'compound': -0.296}\n",
      "-------------\n",
      "THE SHADEEE\n",
      "love the shade towards this nuts, how they fell for this lies and alt right mummy is beyond my reason, also the comedic timing is so on point ðŸ˜‚ðŸ˜‚ðŸ˜‚\n",
      "{'neg': 0.148, 'neu': 0.679, 'pos': 0.173, 'compound': 0.2558}\n",
      "-------------\n",
      "Was she/they completely stoned all of their lives or what???\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "-------------\n",
      "Not unusual..they were also caught worshiping a Mr. Potato Head in their back yard\n",
      "{'neg': 0.0, 'neu': 0.857, 'pos': 0.143, 'compound': 0.25}\n",
      "-------------\n",
      "I would love to know how they mummified her. I know that mummification is historically a very complex and thorough process. i cant wrap my head around a small group of laypeople properly mummifying someone. \n",
      "\n",
      "I have been unable to find anything about it online\n",
      "{'neg': 0.0, 'neu': 0.9, 'pos': 0.1, 'compound': 0.6369}\n",
      "-------------\n",
      "Prosecutors have dropped criminal charges against four of the seven members of the Love Has Won cult, including the man who called himself Father God, according to Saguache County court records.\n",
      "{'neg': 0.133, 'neu': 0.627, 'pos': 0.241, 'compound': 0.6705}\n",
      "-------------\n",
      "I'm trying to figure out what to say all I can say is love her or hate her she's in the arms of God and nothing more can be said..\n",
      "{'neg': 0.103, 'neu': 0.722, 'pos': 0.175, 'compound': 0.3818}\n",
      "-------------\n",
      "I'm trying to figure out what to say all I can say is love her or hate her she's arms of God and nothing more can be said..\n",
      "{'neg': 0.109, 'neu': 0.706, 'pos': 0.185, 'compound': 0.3818}\n",
      "-------------\n",
      "\"Did you folks wake up this morning-\"\n",
      "Me: \"nope\"\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "#init lists\n",
    "text = []\n",
    "neg_score = []\n",
    "neu_score = []\n",
    "pos_score = []\n",
    "compound_score = []\n",
    "\n",
    "for comment in comments:\n",
    "    siaOut = sia.polarity_scores(comment)\n",
    "    \n",
    "    text.append(comment)\n",
    "    neg_score.append(siaOut['neg'])\n",
    "    neu_score.append(siaOut['neu'])\n",
    "    pos_score.append(siaOut['pos'])\n",
    "    compound_score.append(siaOut['compound'])\n",
    "    \n",
    "    print(comment)\n",
    "    print(siaOut)\n",
    "    print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd32433f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>neu_score</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>compound_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oh Iâ€™ve missed you! Iâ€™ve been worried because ...</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No, it isnâ€™t.  (At least not anywhere that Iâ€™m...</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE SHADEEE\\nlove the shade towards this nuts,...</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.2558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Was she/they completely stoned all of their li...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not unusual..they were also caught worshiping ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I would love to know how they mummified her. I...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Prosecutors have dropped criminal charges agai...</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.6705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm trying to figure out what to say all I can...</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I'm trying to figure out what to say all I can...</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Did you folks wake up this morning-\"\\nMe: \"nope\"</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  neg_score  neu_score  \\\n",
       "0  Oh Iâ€™ve missed you! Iâ€™ve been worried because ...      0.251      0.749   \n",
       "1  No, it isnâ€™t.  (At least not anywhere that Iâ€™m...      0.180      0.820   \n",
       "2  THE SHADEEE\\nlove the shade towards this nuts,...      0.148      0.679   \n",
       "3  Was she/they completely stoned all of their li...      0.000      1.000   \n",
       "4  Not unusual..they were also caught worshiping ...      0.000      0.857   \n",
       "5  I would love to know how they mummified her. I...      0.000      0.900   \n",
       "6  Prosecutors have dropped criminal charges agai...      0.133      0.627   \n",
       "7  I'm trying to figure out what to say all I can...      0.103      0.722   \n",
       "8  I'm trying to figure out what to say all I can...      0.109      0.706   \n",
       "9  \"Did you folks wake up this morning-\"\\nMe: \"nope\"      0.000      1.000   \n",
       "\n",
       "   pos_score  compound_score  \n",
       "0      0.000         -0.5707  \n",
       "1      0.000         -0.2960  \n",
       "2      0.173          0.2558  \n",
       "3      0.000          0.0000  \n",
       "4      0.143          0.2500  \n",
       "5      0.100          0.6369  \n",
       "6      0.241          0.6705  \n",
       "7      0.175          0.3818  \n",
       "8      0.185          0.3818  \n",
       "9      0.000          0.0000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe of the comments and their sentiments\n",
    "df = pd.DataFrame({'comment': text,\n",
    "                   'neg_score': neg_score,\n",
    "                   'neu_score': neu_score,\n",
    "                   'pos_score': pos_score,\n",
    "                   'compound_score': compound_score\n",
    "                  })\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c5c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e67c87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b56b5a22",
   "metadata": {},
   "source": [
    "### Tokenize Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c012b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"Resources/Corpus_Podcast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b81827",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file) as f:\n",
    "    raw_text = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tokens(dirty_text):\n",
    "    \n",
    "    big_string = ' '.join(dirty_text).lower() # join and lower into big string\n",
    "    big_string = re.sub(r\"[^a-z0-9'\\s]\", '', big_string) #drop punctuation\n",
    "    big_string = re.sub(r'\\d+', '', big_string) # remove numbers\n",
    "    \n",
    "    tokens = nltk.word_tokenize(big_string) # tokenize with nltk\n",
    "    print(f'Your text is now {len(tokens)} tokens.')\n",
    "    \n",
    "    print(\"Drop it like it's stop.\")\n",
    "    #loop thru words and strip stop words\n",
    "    cleaned_words = []\n",
    "    for token in tokens:\n",
    "        if token not in stopwords.words('english'):\n",
    "            cleaned_words.append(token)\n",
    "            \n",
    "    print(f'Now your text is only {len(cleaned_words)} tokens.')\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba7e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = to_tokens(raw_text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_text(dirty_text):\n",
    "    \n",
    "    big_string = ' '.join(dirty_text).lower() # join and lower into big string\n",
    "    big_string = big_string.replace('.','').replace(',','') #drop commas and periods\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    siaOut = sia.polarity_scores(big_string)\n",
    "    print(siaOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d687896",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d05a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
