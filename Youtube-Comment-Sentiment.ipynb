{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976dcb5b",
   "metadata": {},
   "source": [
    "## Import Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f046e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping tools\n",
    "from urllib.error import HTTPError\n",
    "from datetime import datetime\n",
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# NLP tools\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#import API key\n",
    "from keys import magic_key\n",
    "\n",
    "#viz tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d4e1e4",
   "metadata": {},
   "source": [
    "### Get YouTube Transcript (Currently Broken)\n",
    "\n",
    "Apparently you can't scrape the transcripts the old fashioned way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa474799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Drop in the link to the youtube video.\")\n",
    "# url = input()\n",
    "\n",
    "# # https://www.youtube.com/watch?v=jCZKEnThrjI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68505a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (f'Your url is {url}')\n",
    "# with request.urlopen(url) as response:\n",
    "#     resp = response.read()\n",
    "#     soup = bs(resp, \"html.parser\")\n",
    "#     print(\"Your youtube soup is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b36e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd65b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pull in title and transcript from the soup\n",
    "# lil_soup = soup.find_all(\"div\", id_=\"segments-container\")\n",
    "# print(lil_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d13e1",
   "metadata": {},
   "source": [
    "### Functions that Returns Youtube Comments\n",
    "Uses the Youtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8357e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for getting Youtube comments with the Youtube API\n",
    "def get_comments():\n",
    "    \n",
    "    #get the parameters url from the user and create a \n",
    "    video_url = input(\"Drop in the Youtube Link: \")\n",
    "    print ('Got it! Thanks')\n",
    "    video_id = video_url[32:] #extract the video id from the url\n",
    "    # print(video_id)\n",
    "    \n",
    "    # init API query\n",
    "    comment_url = f\"https://www.googleapis.com/youtube/v3/commentThreads?key={magic_key}\"\n",
    "    params = f\"&textFormat=plainText&part=snippet&videoId={video_id}&maxResults=300\"\n",
    "    title_url = f'https://youtube.googleapis.com/youtube/v3/videos?part=snippet&id={video_id}&key={magic_key}'\n",
    "    \n",
    "    # 1ST API CALL\n",
    "    response = requests.get(title_url).json()\n",
    "    video_title = response['items'][0]['snippet']['title']\n",
    "    \n",
    "    # 2ND API CALL\n",
    "    query_url = comment_url + params\n",
    "    response = requests.get(query_url).json()\n",
    "    \n",
    "    \n",
    "    # LOOP THRU COMMENTS AND GET THAT YUMMY COMMENT TEXT\n",
    "    # response['items'][10] # this is the format of a SINGLE COMM\n",
    "    #raw_comment_list = response['items']\n",
    "\n",
    "    num_comments = response['pageInfo']['totalResults'] # number of comments acutally returned from API\n",
    "    counter = np.arange(0,num_comments) # create list to count thru\n",
    "    print(f'We found {num_comments} comments for {video_title}.')\n",
    "\n",
    "    comments = [video_title]\n",
    "    for c in counter:\n",
    "        comment_text = response['items'][c]['snippet']['topLevelComment']['snippet']['textOriginal']\n",
    "        #print(comment_text)\n",
    "        #print('------------------')\n",
    "        comments.append(comment_text)\n",
    "        \n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a726c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10269e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing function\n",
    "comments = get_comments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e4b733",
   "metadata": {},
   "source": [
    "### Functions to Determine Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f792841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentimental(string_list):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    #init lists\n",
    "    text = []\n",
    "    neg_score = []\n",
    "    neu_score = []\n",
    "    pos_score = []\n",
    "    compound_score = []\n",
    "\n",
    "    for string in string_list:\n",
    "        siaOut = sia.polarity_scores(string)\n",
    "\n",
    "        text.append(string)\n",
    "        neg_score.append(siaOut['neg'])\n",
    "        neu_score.append(siaOut['neu'])\n",
    "        pos_score.append(siaOut['pos'])\n",
    "        compound_score.append(siaOut['compound'])\n",
    "\n",
    "    #     print(comment)\n",
    "    #     print(siaOut)\n",
    "    #     print('-------------')\n",
    "\n",
    "    # create a dataframe of the comments and their sentiments\n",
    "    df = pd.DataFrame({'text': text,\n",
    "                       'neg_score': neg_score,\n",
    "                       'neu_score': neu_score,\n",
    "                       'pos_score': pos_score,\n",
    "                       'compound_score': compound_score\n",
    "                      })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7717aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_sentimental(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b19c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    comments = get_comments()\n",
    "    df = get_sentimental(comments)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b067e548",
   "metadata": {},
   "source": [
    "## Positive Comment Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aabffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on video with positive comments\n",
    "# https://www.youtube.com/watch?v=jCZKEnThrjI&t=7s (Caitlin Doughty and Chelsea Fagan Podcast)\n",
    "\n",
    "test = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average Compound Score {test.compound_score.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcba9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot test (NOT GREAT)\n",
    "plt.scatter(test.index, test.compound_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c3986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swarmplot test (BETTER)\n",
    "sns.swarmplot(x=test.compound_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#density plot (WHAT IS THIS EVEN)\n",
    "test.compound_score.plot(kind='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#violinplot test (I LIKE IT BUT NEED MORE INFO)\n",
    "sns.violinplot(x=test.compound_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843742f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram test\n",
    "plt.hist(test.compound_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278b2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2146700a",
   "metadata": {},
   "source": [
    "## Negative Comment Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39147ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on video with positive comments\n",
    "# https://www.youtube.com/watch?v=YbJOTdZBX1g&t (2018 Youtube Rewind)\n",
    "\n",
    "test_2 = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22599544",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average Compound Score {test_2.compound_score.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot test (NOT GREAT)\n",
    "plt.scatter(test_2.index, test_2.compound_score, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swarmplot test (BETTER)\n",
    "sns.swarmplot(x=test_2.compound_score, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e66326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#density plot (WHAT IS THIS EVEN)\n",
    "test_2.compound_score.plot(kind='density',color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da335319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#violinplot test (I LIKE IT BUT NEED MORE INFO)\n",
    "sns.violinplot(x=test_2.compound_score, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9bcc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram test\n",
    "plt.hist(test_2.compound_score, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f157253",
   "metadata": {},
   "source": [
    "## Comparing the Two Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab42a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['video'] = 'Money and Death Podcast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4332545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2['video'] = '2018 Youtube Rewind'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfcafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.concat([test,test_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d33d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df['dummy'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47431c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.violinplot(data=compare_df, y='compound_score', split=True, hue='video', x='dummy')\n",
    "picture = plot.get_figure()\n",
    "picture.savefig('output.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56b5a22",
   "metadata": {},
   "source": [
    "### Tokenize Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c012b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"Resources/Corpus_Podcast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b81827",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file) as f:\n",
    "    raw_text = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tokens(dirty_text):\n",
    "    \n",
    "    big_string = ' '.join(dirty_text).lower() # join and lower into big string\n",
    "    big_string = re.sub(r\"[^a-z0-9'\\s]\", '', big_string) #drop punctuation\n",
    "    big_string = re.sub(r'\\d+', '', big_string) # remove numbers\n",
    "    \n",
    "    tokens = nltk.word_tokenize(big_string) # tokenize with nltk\n",
    "    print(f'Your text is now {len(tokens)} tokens.')\n",
    "    \n",
    "    print(\"Drop it like it's stop.\")\n",
    "    #loop thru words and strip stop words\n",
    "    cleaned_words = []\n",
    "    for token in tokens:\n",
    "        if token not in stopwords.words('english'):\n",
    "            cleaned_words.append(token)\n",
    "            \n",
    "    print(f'Now your text is only {len(cleaned_words)} tokens.')\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba7e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = to_tokens(raw_text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_text(dirty_text):\n",
    "    \n",
    "    big_string = ' '.join(dirty_text).lower() # join and lower into big string\n",
    "    big_string = big_string.replace('.','').replace(',','') #drop commas and periods\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    siaOut = sia.polarity_scores(big_string)\n",
    "    print(siaOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d687896",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d05a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
